{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset:\n",
    "Contains measurements of different species of iris flowers and is commonly used for classification tasks.\n",
    "\n",
    "-\t150 rows (samples), 5 columns (features + label)\n",
    "-\tTarget (Label): species â†’ The type of iris flower (Iris-setosa, Iris-versicolor, Iris-virginica)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 150\n",
      "Number of columns: 5\n",
      "Column names: Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'species'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing values: \n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n",
      "\n",
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "df = pd.read_csv(url, names=columns)\n",
    "\n",
    "print(f\"Number of rows: {df.shape[0]}\")  # Rows\n",
    "print(f\"Number of columns: {df.shape[1]}\")  # Columns\n",
    "print(f\"Column names: {df.columns}\")  # List of column names\n",
    "print()\n",
    "print(\"Missing values: \")  \n",
    "print(df.isnull().sum()) # Count missing values per column\n",
    "print()\n",
    "print(df.head())  # Show first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "\n",
      "ðŸ”¹ Correlation Matrix from Real Dataset:\n",
      "[[ 1.         -0.10936925  0.87175416  0.81795363]\n",
      " [-0.10936925  1.         -0.4205161  -0.35654409]\n",
      " [ 0.87175416 -0.4205161   1.          0.9627571 ]\n",
      " [ 0.81795363 -0.35654409  0.9627571   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the iris dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Column names based on Iris dataset description\n",
    "columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "df = pd.read_csv(url, names=columns)\n",
    "print(len(df))\n",
    "\n",
    "# Drop the categorical column since we only need numerical features\n",
    "df_numeric = df.drop(columns=[\"species\"])\n",
    "\n",
    "# Step 2: Compute the correlation matrix and convert it to a numpy array\n",
    "correlation_matrix = df_numeric.corr().to_numpy()\n",
    "\n",
    "# Print correlation matrix\n",
    "print(\"\\nðŸ”¹ Correlation Matrix from Real Dataset:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate Dataset\n",
    "\n",
    "### How Are We Turning the Iris Dataset into a Graph Dataset?\n",
    "\n",
    "- 1ï¸âƒ£ Nodes = Dataset features (sepal_length, petal_width, etc.).\n",
    "- 2ï¸âƒ£ Edges = Based on strong correlations in the dataset.\n",
    "- 3ï¸âƒ£ Node Features = Mean values of each feature.\n",
    "- 4ï¸âƒ£ Stored in a PyTorch Geometric Data object for graph-based learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DEBUG: Starting script execution...\n",
      "\n",
      " DEBUG: Dataset class initialized!\n",
      "Printing processed path for the first time: /tmp/dataset_folder/processed/graph_data.pt\n",
      "\n",
      " DEBUG: Deleting existing dataset: /tmp/dataset_folder/processed/graph_data.pt\n",
      "DEBUG: Calling process() now...\n",
      "DEBUG: process() method is running...\n",
      "\n",
      " DEBUG: Loading dataset...\n",
      "\n",
      " DEBUG: Dataset loaded successfully!\n",
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "\n",
      " DEBUG: Computing correlation matrix...\n",
      "\n",
      " DEBUG: Correlation matrix computed!\n",
      "[[ 1.         -0.10936925  0.87175416  0.81795363]\n",
      " [-0.10936925  1.         -0.4205161  -0.35654409]\n",
      " [ 0.87175416 -0.4205161   1.          0.9627571 ]\n",
      " [ 0.81795363 -0.35654409  0.9627571   1.        ]]\n",
      "\n",
      " DEBUG: Extracting edges...\n",
      "!!!!Edges (array([0, 0, 0, 1, 2, 2, 2, 3, 3, 3]), array([0, 2, 3, 1, 0, 2, 3, 0, 2, 3]))\n",
      "\n",
      " DEBUG: Edges extracted!\n",
      "tensor([[0, 0, 0, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [0, 2, 3, 1, 0, 2, 3, 0, 2, 3]])\n",
      "\n",
      " DEBUG: Computing node features...\n",
      "sepal_length    5.843333\n",
      "sepal_width     3.054000\n",
      "petal_length    3.758667\n",
      "petal_width     1.198667\n",
      "dtype: float64\n",
      "\n",
      " DEBUG: Node features created!\n",
      "\n",
      "ðŸ”¹ Final Node Features (x):\n",
      "tensor([[5.8433],\n",
      "        [3.0540],\n",
      "        [3.7587],\n",
      "        [1.1987]])\n",
      "\n",
      " DEBUG: Creating graph data object...\n",
      "\n",
      " DEBUG: Graph Data Object created!\n",
      "Data(x=[4, 1], edge_index=[2, 10])\n",
      "\n",
      " DEBUG: Saving dataset...\n",
      "\n",
      " DEBUG: Dataset saved successfully!\n",
      "CorrelationGraphDataset()\n",
      "\n",
      " DEBUG: Dataset instance created successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os #manages file system operations \n",
    "\n",
    "class CorrelationGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset and forces processing by deleting old data.\n",
    "        \"\"\"\n",
    "        print(\"\\n DEBUG: Dataset class initialized!\")  # Print when dataset is created\n",
    "\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "        # FORCE PROCESSING BY DELETING OLD DATA\n",
    "        processed_path = self.processed_paths[0]\n",
    "        print(\"Printing processed path for the first time:\", processed_path)\n",
    "        if os.path.exists(processed_path):\n",
    "            print(f\"\\n DEBUG: Deleting existing dataset: {processed_path}\")\n",
    "            os.remove(processed_path)  # Remove old processed file to force reprocessing\n",
    "\n",
    "        print(\"DEBUG: Calling process() now...\")\n",
    "        self.process()\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"Defines the processed dataset file name.\"\"\"\n",
    "        return ['graph_data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Converts a real correlation matrix into a PyTorch Geometric dataset.\n",
    "        \"\"\"\n",
    "        print(\"DEBUG: process() method is running...\")  # Print first thing inside process()\n",
    "\n",
    "        # Step 1: Load a real dataset (Iris dataset)\n",
    "        print(\"\\n DEBUG: Loading dataset...\")\n",
    "        url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "        columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "        df = pd.read_csv(url, names=columns)\n",
    "\n",
    "        print(\"\\n DEBUG: Dataset loaded successfully!\")\n",
    "        print(df.head())  # Show first few rows\n",
    "\n",
    "        # Drop categorical column\n",
    "        df_numeric = df.drop(columns=[\"species\"])\n",
    "\n",
    "        # Compute correlation matrix\n",
    "        print(\"\\n DEBUG: Computing correlation matrix...\")\n",
    "        correlation_matrix = df_numeric.corr().to_numpy()\n",
    "\n",
    "        print(\"\\n DEBUG: Correlation matrix computed!\")\n",
    "        print(correlation_matrix)  # Show matrix\n",
    "\n",
    "        # Extract edges\n",
    "        print(\"\\n DEBUG: Extracting edges...\")\n",
    "        threshold = 0.6  # Keep strong correlations\n",
    "        edges = np.where(np.abs(correlation_matrix) > threshold)\n",
    "        print(\"!!!!Edges\", edges)\n",
    "        edge_index = torch.tensor(np.array(edges), dtype=torch.long)\n",
    "\n",
    "        print(\"\\n DEBUG: Edges extracted!\")\n",
    "        print(edge_index)\n",
    "\n",
    "        # Step 3: Create node features\n",
    "        print(\"\\n DEBUG: Computing node features...\")\n",
    "        print(df_numeric.mean())  # Print mean before conversion\n",
    "\n",
    "        try:\n",
    "            node_features = torch.tensor(df_numeric.mean().to_numpy().reshape(-1, 1), dtype=torch.float)\n",
    "            print(\"\\n DEBUG: Node features created!\")\n",
    "        except Exception as e:\n",
    "            print(\"\\n ERROR in node feature conversion:\", e)\n",
    "            return\n",
    "\n",
    "        print(\"\\nðŸ”¹ Final Node Features (x):\")\n",
    "        print(node_features)\n",
    "\n",
    "        # Create a PyG `Data` object\n",
    "        print(\"\\n DEBUG: Creating graph data object...\")\n",
    "        graph_data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "        print(\"\\n DEBUG: Graph Data Object created!\")\n",
    "        print(graph_data)\n",
    "\n",
    "        # Save dataset\n",
    "        print(\"\\n DEBUG: Saving dataset...\")\n",
    "        self.save([graph_data], self.processed_paths[0])\n",
    "\n",
    "        print(\"\\n DEBUG: Dataset saved successfully!\")\n",
    "\n",
    "# Ensure script runs correctly\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n DEBUG: Starting script execution...\")\n",
    "\n",
    "    # Create dataset instance\n",
    "    dataset = CorrelationGraphDataset(root=\"/tmp/dataset_folder\") \n",
    "    print(dataset) \n",
    "  \n",
    "    print(\"\\n DEBUG: Dataset instance created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61c12dabc53b3c38026121b5b57a874e2c527979eaaf65ce1b82c6f270ed05c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
